# Étape 0 : Application Minimale Déployable

**Objectif** : Avoir une application Next.js qui tourne et qui est déployée sur Render.com

## Ce qu'on livre

- Une page d'accueil avec le titre "CoTiTra"
- Build réussi
- Déploiement fonctionnel sur Render.com

## Tâches

- [x] Initialiser Next.js 16 avec TypeScript et Tailwind
- [x] Créer une page d'accueil minimaliste
- [x] Vérifier que `npm run build` fonctionne
- [x] Créer un repository GitHub
- [x] Déployer sur Render.com
- [x] Vérifier que l'application est accessible en ligne (https://copro-tickets-tracker.onrender.com/)

## Validation

- ✅ L'URL Render.com affiche "CoTiTra"
- ✅ Le build passe sans erreur

---

# Étape 0b : Bloquer le Référencement par les Moteurs de Recherche

**Objectif** : Empêcher l'application déployée d'être référencée par les moteurs de recherche (Google, Bing, etc.)

## Ce qu'on livre

- Fichier robots.txt qui bloque tous les robots d'indexation
- Meta tag noindex dans les métadonnées de l'application
- Header HTTP X-Robots-Tag: noindex
- L'application reste accessible par URL directe mais ne sera pas indexée

## Tâches

- [x] Créer le fichier `app/robots.ts` avec une fonction qui retourne la configuration robots.txt
- [x] Ajouter la meta tag `robots: noindex, nofollow` dans `app/layout.tsx` (metadata)
- [x] Configurer le header `X-Robots-Tag: noindex, nofollow` dans `next.config.ts`
- [x] Tester en local que robots.txt est accessible (`http://localhost:3000/robots.txt`)
- [x] Vérifier les headers HTTP en local (Outils dev → Network)
- [ ] Déployer sur Render.com
- [ ] Vérifier que robots.txt est accessible en production (`https://copro-tickets-tracker.onrender.com/robots.txt`)
- [ ] Vérifier les headers HTTP en production

## Validation

- ✅ `/robots.txt` affiche `User-agent: * Disallow: /`
- ✅ Le HTML contient `<meta name="robots" content="noindex, nofollow">`
- ✅ Les réponses HTTP contiennent le header `X-Robots-Tag: noindex, nofollow`
- ✅ L'application reste accessible et fonctionnelle
- ⏳ Déployé en production (en attente du push git)

## Notes techniques

**robots.txt via Next.js** :

Next.js 15 permet de générer robots.txt dynamiquement via un fichier `app/robots.ts` :

```typescript
import { MetadataRoute } from 'next';

export default function robots(): MetadataRoute.Robots {
  return {
    rules: {
      userAgent: '*',
      disallow: '/',
    },
  };
}
```

**Meta tag robots** :

Dans `app/layout.tsx`, ajouter dans les métadonnées :

```typescript
export const metadata: Metadata = {
  // ... autres métadonnées
  robots: {
    index: false,
    follow: false,
  },
};
```

**Header HTTP X-Robots-Tag** :

Dans `next.config.ts`, ajouter :

```typescript
const nextConfig: NextConfig = {
  async headers() {
    return [
      {
        source: '/:path*',
        headers: [
          {
            key: 'X-Robots-Tag',
            value: 'noindex, nofollow',
          },
        ],
      },
    ];
  },
};
```

**Pourquoi trois méthodes ?**

- **robots.txt** : Standard universel, tous les robots le respectent
- **Meta tag** : Backup pour les pages HTML, lu par les robots qui analysent le contenu
- **Header HTTP** : Protège même les ressources non-HTML (API, images, etc.)

Cette triple protection garantit qu'aucun moteur de recherche n'indexera l'application.

---

# Étape 0c : Tests E2E et Vérification des Headers HTTP

**Objectif** : Valider automatiquement que les headers HTTP et robots.txt fonctionnent correctement

## Ce qu'on livre

- Infrastructure de tests End-to-End avec Playwright
- Tests automatisés des headers `X-Robots-Tag`
- Tests du fichier `robots.txt`
- Intégration dans la CI/CD GitHub Actions

## Tâches

- [x] Installer Playwright (`@playwright/test`)
- [x] Créer `playwright.config.ts`
- [x] Créer `tests/e2e/headers.spec.ts` (tests headers HTTP + meta tags)
- [x] Créer `tests/e2e/robots.spec.ts` (tests robots.txt)
- [x] Créer `tests/e2e/smoke.spec.ts` (tests de fumée)
- [x] Ajouter scripts npm (`test:e2e`, `test:e2e:ui`, `test:e2e:debug`)
- [x] Mettre à jour `.gitignore` pour Playwright
- [x] Intégrer dans `.github/workflows/ci.yml`
- [x] Tester en local (`npm run test:e2e`)
- [ ] Tester sur une PR

## Validation

- ✅ Les tests e2e passent en local (11/11 tests)
- ✅ Header `X-Robots-Tag: noindex, nofollow` vérifié sur toutes les routes
- ✅ `/robots.txt` accessible et contient `Disallow: /`
- ✅ Meta tags `noindex, nofollow` présents dans le HTML
- ⏳ Tests e2e passent dans GitHub Actions (à tester sur PR)

## Notes techniques

**Commandes Playwright** :

```bash
npm run test:e2e           # Lancer les tests e2e
npm run test:e2e:ui        # Mode UI (interface graphique)
npm run test:e2e:debug     # Mode debug
```
